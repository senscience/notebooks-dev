{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marine Biodiversity and Environmental Data Exploration with `mlcroissant`\n",
    "This notebook provides a template for loading and exploring a dataset using the `mlcroissant` library.\n",
    "\n",
    "### Dataset Source\n",
    "The dataset source is provided via a Croissant schema URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure `mlcroissant` library is installed\n",
    "!pip install mlcroissant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "Load metadata and records from the dataset using `mlcroissant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "import pandas as pd\n",
    "\n",
    "# Define the dataset URL\n",
    "url = 'https://dev.senscience.cloud/portal/10.82843/pm80-mh77/fair2.json'\n",
    "\n",
    "# Load the dataset metadata\n",
    "dataset = mlc.Dataset(url)\n",
    "metadata = dataset.metadata\n",
    "print(f\"{metadata.name}: {metadata.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview\n",
    "Review available record sets, fields, and their IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record_set in metadata.recordSet:\n",
    "    print(f\"Record Set ID: {record_set['@id']} - Description: {record_set['description']}\")\n",
    "    for field in record_set['field']:\n",
    "        print(f\"  Field ID: {field['@id']} - Name: {field['name']} - DataType: {field['dataType']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Extraction\n",
    "Load data from a specific record set into a DataFrame for analysis. Use the record set and field `@id`s from the overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from each record set\n",
    "record_sets = [\n",
    "    'https://senscience.ai/frontiers/borja/README.csv',\n",
    "    'https://senscience.ai/frontiers/borja/METADATA.csv',\n",
    "    'https://senscience.ai/frontiers/borja/WATER.csv'\n",
    "]\n",
    "dataframes = {}\n",
    "\n",
    "for record_set in record_sets:\n",
    "    records = list(dataset.records(record_set=record_set))\n",
    "    dataframes[record_set] = pd.DataFrame(records)\n",
    "\n",
    "# Print columns of one of the dataframes\n",
    "print(dataframes['https://senscience.ai/frontiers/borja/METADATA.csv'].columns.tolist())\n",
    "dataframes['https://senscience.ai/frontiers/borja/METADATA.csv'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "Apply common data processing steps, such as filtering records based on specific criteria, normalizing numeric fields, and categorizing data. This section should include operations like removing outliers, transforming data distributions, or grouping data by key attributes to prepare it for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Select a numeric field for analysis\n",
    "numeric_field = 'https://senscience.ai/frontiers/borja/METADATA.csv/decimallatitude'\n",
    "\n",
    "threshold = 43.4\n",
    "filtered_df = dataframes['https://senscience.ai/frontiers/borja/METADATA.csv'][\n",
    "    dataframes['https://senscience.ai/frontiers/borja/METADATA.csv'][numeric_field] > threshold\n",
    "]\n",
    "print(f\"Filtered records with {numeric_field} > {threshold}:\")\n",
    "print(filtered_df.head())\n",
    "\n",
    "# Normalizing the selected numeric field\n",
    "filtered_df[f\"{numeric_field}_normalized\"] = (\n",
    "    filtered_df[numeric_field] - filtered_df[numeric_field].mean()\n",
    ") / filtered_df[numeric_field].std()\n",
    "print(f\"Normalized {numeric_field} for filtered records:\")\n",
    "print(filtered_df[[numeric_field, f\"{numeric_field}_normalized\"]].head())\n",
    "\n",
    "group_field = 'https://senscience.ai/frontiers/borja/METADATA.csv/sitename'\n",
    "if group_field in dataframes['https://senscience.ai/frontiers/borja/METADATA.csv'].columns:\n",
    "    grouped_df = filtered_df.groupby(group_field).mean()\n",
    "    print(f\"Grouped data by {group_field}:\")\n",
    "    print(grouped_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "Visualize data distributions or relationships between fields in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the normalized latitude values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(\n",
    "    filtered_df[f\"{numeric_field}_normalized\"],\n",
    "    bins=20,\n",
    "    color='c',\n",
    "    edgecolor='k'\n",
    ")\n",
    "plt.title('Distribution of Normalized Decimal Latitude')\n",
    "plt.xlabel('Normalized Latitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "Summarize key findings and observations from the dataset exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we explored the Marine Biodiversity and Environmental Data dataset using the `mlcroissant` library. We successfully loaded the dataset, examined its structure, and performed basic exploratory data analysis. By filtering and normalizing the latitude data, we were able to visualize the distribution and gain insights into the geographic spread of the sampling sites. Further analysis could include exploring additional fields and relationships within the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}