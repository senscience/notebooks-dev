{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marine Biodiversity and Environmental Data Exploration with `mlcroissant`\n",
    "This notebook provides a guide for loading and exploring a dataset using the `mlcroissant` library.\n",
    "\n",
    "### Dataset Source\n",
    "The dataset source is provided via a Croissant schema URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure `mlcroissant` library is installed\n",
    "!pip install mlcroissant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "Load metadata and records from the dataset using `mlcroissant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "import pandas as pd\n",
    "\n",
    "# Define the dataset URL\n",
    "url = 'https://cdn.dev.senscience.cloud/portals/10.82843/pm80-mh77/fair2.json'\n",
    "\n",
    "# Load the dataset metadata\n",
    "dataset = mlc.Dataset(url)\n",
    "metadata = dataset.metadata.to_json()\n",
    "print(f\"{metadata['name']}: {metadata['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview\n",
    "Review available record sets, fields, and their IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the record sets available in the dataset\n",
    "record_sets = metadata['recordSet']\n",
    "for record_set in record_sets:\n",
    "    print(f\"Record Set ID: {record_set['@id']}\")\n",
    "    print(f\"Description: {record_set['description']}\")\n",
    "    for field in record_set['field']:\n",
    "        print(f\"  Field ID: {field['@id']}, Name: {field['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Extraction\n",
    "Load data from a specific record set into a DataFrame for analysis. Use the record set and field `@id`s from the overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from each record set\n",
    "record_set_id = 'https://senscience.ai/frontiers/borja/WATER.csv'  # Example Record Set ID\n",
    "records = list(dataset.records(record_set=record_set_id))\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "print(df.columns.tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "Apply common data processing steps, such as filtering records based on specific criteria, normalizing numeric fields, and categorizing data. This section should include operations like removing outliers, transforming data distributions, or grouping data by key attributes to prepare it for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a numeric field for analysis\n",
    "numeric_field = 'https://api.dev.senscience.cloud/frontiers/8704cfcf-0667-4eaf-b0b1-679597df683f-16/1cf446bb-deb7-4b51-8958-0561d8c9668c'\n",
    "\n",
    "# Filter records with a threshold\n",
    "threshold = 10\n",
    "filtered_df = df[df[numeric_field] > threshold]\n",
    "print(f\"Filtered records with {numeric_field} > {threshold}:\")\n",
    "print(filtered_df.head())\n",
    "\n",
    "# Normalize the numeric field\n",
    "filtered_df[f\"{numeric_field}_normalized\"] = (filtered_df[numeric_field] - filtered_df[numeric_field].mean()) / filtered_df[numeric_field].std()\n",
    "print(f\"Normalized {numeric_field} for filtered records:\")\n",
    "print(filtered_df[[numeric_field, f\"{numeric_field}_normalized\"]].head())\n",
    "\n",
    "# Group by another field\n",
    "group_field = 'siteid'\n",
    "if group_field in df.columns:\n",
    "    grouped_df = filtered_df.groupby(group_field).mean()\n",
    "    print(f\"Grouped data by {group_field}:\")\n",
    "    print(grouped_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "Visualize data distributions or relationships between fields in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the distribution of the normalized values\n",
    "plt.figure(figsize=(10, 6))\n",
    "filtered_df[f\"{numeric_field}_normalized\"].hist(bins=50)\n",
    "plt.title('Distribution of Normalized Parameter Values')\n",
    "plt.xlabel('Normalized Parameter Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "Summarize key findings and observations from the dataset exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we successfully loaded and explored a dataset using the `mlcroissant` library. We reviewed the available record sets and fields, extracted data into a DataFrame, and performed basic exploratory data analysis. Key findings include the distribution patterns of parameter values and insights into site-specific data groupings. This analysis provides a foundation for further in-depth research and data modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
