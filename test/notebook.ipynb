{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marine Biodiversity and Environmental Data Exploration with `mlcroissant`\n",
    "This notebook provides an example of loading and exploring the Marine Biodiversity and Environmental Data dataset using the `mlcroissant` library.\n",
    "\n",
    "### Dataset Source\n",
    "The dataset source is provided via a Croissant schema URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure `mlcroissant` library is installed\n",
    "!pip install mlcroissant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "Load metadata and records from the dataset using `mlcroissant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "import pandas as pd\n",
    "\n",
    "# Define the dataset URL\n",
    "url = 'https://dev.senscience.cloud/portal/10.82843/pm80-mh77/fair2.json'\n",
    "\n",
    "# Load the dataset metadata\n",
    "dataset = mlc.Dataset(url)\n",
    "metadata = dataset.metadata\n",
    "print(f\"{metadata.name}: {metadata.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview\n",
    "Review available record sets, fields, and their IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display record sets and field IDs\n",
    "record_sets = metadata.recordSet\n",
    "for record_set in record_sets:\n",
    "    print(f\"Record Set ID: {record_set['@id']}\")\n",
    "    for field in record_set['field']:\n",
    "        print(f\"  Field ID: {field['@id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Extraction\n",
    "Load data from a specific record set into a DataFrame for analysis. Use the record set and field `@id`s from the overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from each record set\n",
    "record_sets_ids = [\n",
    "    'https://senscience.ai/frontiers/borja/README.csv',\n",
    "    'https://senscience.ai/frontiers/borja/METADATA.csv',\n",
    "    'https://senscience.ai/frontiers/borja/WATER.csv'\n",
    "]\n",
    "dataframes = {}\n",
    "\n",
    "for record_set_id in record_sets_ids:\n",
    "    records = list(dataset.records(record_set=record_set_id))\n",
    "    dataframes[record_set_id] = pd.DataFrame(records)\n",
    "\n",
    "# Display columns of a chosen record set\n",
    "print(dataframes['https://senscience.ai/frontiers/borja/METADATA.csv'].columns.tolist())\n",
    "dataframes['https://senscience.ai/frontiers/borja/METADATA.csv'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "Apply common data processing steps, such as filtering records based on specific criteria, normalizing numeric fields, and categorizing data. This section should include operations like removing outliers, transforming data distributions, or grouping data by key attributes to prepare it for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a numeric field for analysis\n",
    "numeric_field = 'https://senscience.ai/frontiers/borja/METADATA.csv/decimallatitude'\n",
    "\n",
    "threshold = 43.35\n",
    "filtered_df = dataframes['https://senscience.ai/frontiers/borja/METADATA.csv'][\n",
    "    dataframes['https://senscience.ai/frontiers/borja/METADATA.csv'][numeric_field] > threshold\n",
    "]\n",
    "print(f\"Filtered records with {numeric_field} > {threshold}:\")\n",
    "print(filtered_df.head())\n",
    "\n",
    "# Normalize the numeric field for the filtered records\n",
    "filtered_df[f\"{numeric_field}_normalized\"] = (\n",
    "    filtered_df[numeric_field] - filtered_df[numeric_field].mean()\n",
    ") / filtered_df[numeric_field].std()\n",
    "print(f\"Normalized {numeric_field} for filtered records:\")\n",
    "print(filtered_df[[numeric_field, f\"{numeric_field}_normalized\"]].head())\n",
    "\n",
    "# Grouping the data by site ID\n",
    "group_field = 'https://senscience.ai/frontiers/borja/METADATA.csv/siteid'\n",
    "if group_field in dataframes['https://senscience.ai/frontiers/borja/METADATA.csv'].columns:\n",
    "    grouped_df = filtered_df.groupby(group_field).mean()\n",
    "    print(f\"Grouped data by {group_field}:\")\n",
    "    print(grouped_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "Visualize data distributions or relationships between fields in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the distribution of a numeric field\n",
    "plt.hist(\n",
    "    filtered_df[numeric_field],\n",
    "    bins=30,\n",
    "    alpha=0.7,\n",
    "    color='blue',\n",
    "    label=f'{numeric_field} Distribution'\n",
    ")\n",
    "plt.xlabel('Latitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Latitude in Filtered Records')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "Summarize key findings and observations from the dataset exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we explored the Marine Biodiversity and Environmental Data dataset using the `mlcroissant` library. We successfully loaded metadata, reviewed available record sets and fields, extracted data from specific record sets, and performed an exploratory data analysis. Filtering and normalizing latitude data provided insights into the geographic distribution of sampling sites. The visualization further illustrated the distribution of these sample sites' latitudes. This analysis can be extended to include more complex data processing and machine learning tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}