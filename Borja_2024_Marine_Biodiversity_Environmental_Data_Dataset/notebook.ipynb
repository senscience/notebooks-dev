{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marine Biodiversity and Environmental Data Exploration with `mlcroissant`\n",
    "This notebook provides a step-by-step guide for loading and exploring a dataset using the `mlcroissant` library.\n",
    "\n",
    "### Dataset Source\n",
    "The dataset source is provided via a Croissant schema URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure `mlcroissant` library is installed\n",
    "!pip install mlcroissant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "Load metadata and records from the dataset using `mlcroissant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "import pandas as pd\n",
    "\n",
    "# Define the dataset URL\n",
    "url = 'https://cdn.dev.senscience.cloud/portals/10.82843/pm80-mh77/fair2.json'\n",
    "\n",
    "# Load the dataset metadata\n",
    "dataset = mlc.Dataset(url)\n",
    "metadata = dataset.metadata\n",
    "print(f\"{metadata['name']}: {metadata['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview\n",
    "Review available record sets, fields, and their IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available record sets\n",
    "record_sets = metadata['recordSet']\n",
    "for record_set in record_sets:\n",
    "    print(f\"Record Set: {record_set['@id']}, Description: {record_set['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Extraction\n",
    "Load data from a specific record set into a DataFrame for analysis. Use the record set and field `@id`s from the overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from each record set\n",
    "record_sets_ids = [\n",
    "    'https://senscience.ai/frontiers/borja/README.csv',\n",
    "    'https://senscience.ai/frontiers/borja/METADATA.csv',\n",
    "    'https://senscience.ai/frontiers/borja/WATER.csv'\n",
    "]\n",
    "dataframes = {}\n",
    "\n",
    "for record_set_id in record_sets_ids:\n",
    "    records = list(dataset.records(record_set=record_set_id))\n",
    "    dataframes[record_set_id] = pd.DataFrame(records)\n",
    "\n",
    "print(dataframes['https://senscience.ai/frontiers/borja/WATER.csv'].columns.tolist())\n",
    "dataframes['https://senscience.ai/frontiers/borja/WATER.csv'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "Apply common data processing steps, such as filtering records based on specific criteria, normalizing numeric fields, and categorizing data. This section should include operations like removing outliers, transforming data distributions, or grouping data by key attributes to prepare it for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a numeric field for analysis\n",
    "numeric_field = 'maximumdepthinmeters'\n",
    "record_set_id = 'https://senscience.ai/frontiers/borja/WATER.csv'\n",
    "\n",
    "threshold = 10\n",
    "filtered_df = dataframes[record_set_id][dataframes[record_set_id][numeric_field] > threshold]\n",
    "print(f\"Filtered records with {numeric_field} > {threshold}:\")\n",
    "print(filtered_df.head())\n",
    "\n",
    "filtered_df[f\"{numeric_field}_normalized\"] = (filtered_df[numeric_field] - filtered_df[numeric_field].mean()) / filtered_df[numeric_field].std()\n",
    "print(f\"Normalized {numeric_field} for filtered records:\")\n",
    "print(filtered_df[[numeric_field, f\"{numeric_field}_normalized\"]].head())\n",
    "\n",
    "group_field = 'parameter'\n",
    "if group_field in dataframes[record_set_id].columns:\n",
    "    grouped_df = filtered_df.groupby(group_field).mean()\n",
    "    print(f\"Grouped data by {group_field}:\")\n",
    "    print(grouped_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "Visualize data distributions or relationships between fields in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot histogram of parameter values\n",
    "plt.figure(figsize=(10, 6))\n",
    "filtered_df[numeric_field].hist(bins=50)\n",
    "plt.title('Histogram of Maximum Sampling Depth')\n",
    "plt.xlabel('Depth (meters)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "Summarize key findings and observations from the dataset exploration.\n",
    "\n",
    "- The dataset provides extensive environmental monitoring data across various aquatic environments.\n",
    "- Initial data filtering and normalization reveal insights into sampling depths and parameters measured.\n",
    "- Visual analysis helps in understanding the distribution of key environmental factors.\n",
    "- Further analysis could involve examining temporal trends or correlations between different environmental variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}